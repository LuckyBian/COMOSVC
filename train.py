import argparse
import torch
from loguru import logger
from torch.optim import lr_scheduler
import os

from data_loaders import get_data_loaders
import utils
from solver import train
from ComoSVC import ComoSVC
from Vocoder import Vocoder
from utils import load_teacher_model_with_pitch, traverse_dir

def parse_args():
    parser = argparse.ArgumentParser(description="Train ComoSVC")

    parser.add_argument(
        "--config", "-c",
        type=str,
        default="configs/diffusion.yaml",
        help="è·¯å¾„ï¼šé…ç½®æ–‡ä»¶ (.yml)"
    )

    parser.add_argument(
        "--mode", "-m",
        type=str,
        choices=["teacher", "student"],
        default="teacher",
        help="è®­ç»ƒæ¨¡å¼ï¼šteacher è¡¨ç¤ºå¾®è°ƒæ•™å¸ˆæ¨¡å‹ï¼Œstudent è¡¨ç¤ºè’¸é¦å­¦ç”Ÿæ¨¡å‹"
    )

    parser.add_argument(
        "--teacher_model_path", "-p",
        type=str,
        default="logs/teacher/model_800000.pt",
        help="æ•™å¸ˆæ¨¡å‹è·¯å¾„ï¼ˆç”¨äº student æ¨¡å¼åŠ è½½ï¼‰"
    )

    return parser.parse_args()


if __name__ == "__main__":
    cmd = parse_args()

    # åŠ è½½é…ç½®
    args = utils.load_config(cmd.config)
    logger.info(f"âœ… Loaded config: {cmd.config}")

    # åŠ è½½ vocoder
    vocoder = Vocoder(args.vocoder.type, args.vocoder.ckpt, device=args.device)

    # æ˜¯å¦æ˜¯ teacher æ¨¡å¼
    is_teacher = (cmd.mode == "teacher")

    # åˆå§‹åŒ–æ¨¡å‹
    model = ComoSVC(
        args.data.encoder_out_channels,
        args.model.n_spk,
        args.model.use_pitch_aug,
        vocoder.dimension,
        args.model.n_layers,
        args.model.n_chans,
        args.model.n_hidden,
        teacher=is_teacher
    )

    if is_teacher:
        optimizer = torch.optim.AdamW(model.parameters(), lr=args.train.lr)
        initial_global_step, model, optimizer = utils.load_model(
            args.env.expdir, model, optimizer, device=args.device
        )
        logger.info("ğŸš€ The Teacher Model is training now.")
    else:
        # åŠ è½½ teacher æ¨¡å‹å‚æ•°ï¼ˆå†»ç»“/æå–ç‰¹å¾ç”¨ï¼‰
        model = load_teacher_model_with_pitch(model, checkpoint_dir=cmd.teacher_model_path)
        optimizer = torch.optim.AdamW(params=model.decoder.denoise_fn.parameters())
        path_pt = traverse_dir(args.env.comodir, ['pt'], is_ext=False)
        if len(path_pt) > 0:
            initial_global_step, model, optimizer = utils.load_model(
                args.env.comodir, model, optimizer, device=args.device
            )
        else:
            initial_global_step = 0
        logger.info("ğŸ§  The Student Model (CoMoSVC) is training now.")

    # è®¾ç½®å­¦ä¹ ç‡ã€æƒé‡è¡°å‡
    for param_group in optimizer.param_groups:
        if is_teacher:
            param_group['initial_lr'] = args.train.lr
            param_group['lr'] = args.train.lr * (args.train.gamma ** max(((initial_global_step - 2) // args.train.decay_step), 0)) * 2
        else:
            param_group['initial_lr'] = args.train.comolr
            param_group['lr'] = args.train.comolr * (args.train.gamma ** max(((initial_global_step - 2) // args.train.decay_step), 0))
        param_group['weight_decay'] = args.train.weight_decay

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = lr_scheduler.StepLR(
        optimizer,
        step_size=args.train.decay_step,
        gamma=args.train.gamma,
        last_epoch=initial_global_step - 2
    )

    # è®¾ç½® GPU
    if args.device == 'cuda':
        torch.cuda.set_device(args.env.gpu_id)
    model.to(args.device)

    # æŠŠ optimizer é‡Œçš„ tensor ç§»åŠ¨åˆ° GPU
    for state in optimizer.state.values():
        for k, v in state.items():
            if torch.is_tensor(v):
                state[k] = v.to(args.device)

    # æ•°æ®åŠ è½½å™¨
    loader_train, loader_valid = get_data_loaders(args, whole_audio=False)

    # å¯åŠ¨è®­ç»ƒ
    train(args, initial_global_step, model, optimizer, scheduler, vocoder, loader_train, loader_valid, teacher=is_teacher)
